{
  "description": "Model selection configuration for RealtimeSTT-mac conversion pipeline",
  "models": {
    "tiny.en": {
      "include": true,
      "source_repo": "openai/whisper-tiny.en",
      "priority": 1,
      "notes": "Fastest model, English-only",
      "conversion_files": ["tokenizer.json"]
    },
    "tiny": {
      "include": true,
      "source_repo": "openai/whisper-tiny",
      "priority": 2,
      "notes": "Fastest model, multilingual",
      "conversion_files": ["tokenizer.json"]
    },
    "base.en": {
      "include": true,
      "source_repo": "openai/whisper-base.en",
      "priority": 3,
      "notes": "Good balance, English-only",
      "conversion_files": ["tokenizer.json"]
    },
    "base": {
      "include": true,
      "source_repo": "openai/whisper-base",
      "priority": 4,
      "notes": "Good balance, multilingual",
      "conversion_files": ["tokenizer.json"]
    },
    "small.en": {
      "include": true,
      "source_repo": "openai/whisper-small.en",
      "priority": 5,
      "notes": "Better accuracy, English-only",
      "conversion_files": ["tokenizer.json"]
    },
    "small": {
      "include": true,
      "source_repo": "openai/whisper-small",
      "priority": 6,
      "notes": "Better accuracy, multilingual",
      "conversion_files": ["tokenizer.json"]
    },
    "medium.en": {
      "include": true,
      "source_repo": "openai/whisper-medium.en",
      "priority": 7,
      "notes": "High accuracy, English-only",
      "conversion_files": ["tokenizer.json"]
    },
    "medium": {
      "include": true,
      "source_repo": "openai/whisper-medium",
      "priority": 8,
      "notes": "High accuracy, multilingual",
      "conversion_files": ["tokenizer.json"]
    },
    "large-v1": {
      "include": true,
      "source_repo": "openai/whisper-large-v1",
      "priority": 9,
      "notes": "Highest accuracy, v1",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "large-v2": {
      "include": true,
      "source_repo": "openai/whisper-large-v2",
      "priority": 10,
      "notes": "Highest accuracy, v2",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "large-v3": {
      "include": true,
      "source_repo": "openai/whisper-large-v3",
      "priority": 11,
      "notes": "Latest and best accuracy",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "distil-large-v2": {
      "include": true,
      "source_repo": "distil-whisper/distil-large-v2",
      "priority": 12,
      "notes": "Distilled version, faster inference",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "distil-medium.en": {
      "include": true,
      "source_repo": "distil-whisper/distil-medium.en",
      "priority": 13,
      "notes": "Distilled medium, English-only",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "distil-small.en": {
      "include": true,
      "source_repo": "distil-whisper/distil-small.en",
      "priority": 14,
      "notes": "Distilled small, English-only",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "distil-large-v3": {
      "include": true,
      "source_repo": "distil-whisper/distil-large-v3",
      "priority": 15,
      "notes": "Latest distilled version",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    },
    "distil-large-v3.5": {
      "include": true,
      "source_repo": "distil-whisper/distil-large-v3.5",
      "priority": 16,
      "notes": "Newest distilled version",
      "conversion_files": ["tokenizer.json", "preprocessor_config.json"]
    }
  },
  "conversion_settings": {
    "base_command": "ct2-transformers-converter",
    "default_quantization": "float32",
    "fallback_quantization": "float16",
    "output_dir_pattern": "{model_name}-fp32",
    "force_conversion": true
  },
  "settings": {
    "process_only_included": true,
    "respect_priority_order": true,
    "skip_existing_repos": false,
    "batch_size": 1,
    "notes": "Set include=true for models you want to process. Now uses original OpenAI/distil-whisper models as sources for FP32 conversion."
  }
}
